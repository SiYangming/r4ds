# Data import | 数据导入

## Introduction | 简介

Working with data provided by R packages is a great way to learn the tools of data science, but at some point you want to stop learning and start working with your own data. In this chapter, you'll learn how to read plain-text rectangular files into R. Here, we'll only scratch the surface of data import, but many of the principles will translate to other forms of data. We'll finish with a few pointers to packages that are useful for other types of data.

使用 R 包提供的数据是学习数据科学工具的良好方法，但你总要在某个时间停止学习，开始处理自己的数据。你将在本章中学习如何将纯文本格式的矩形文件读入 R。虽然本章内容只是数据导入的冰山一角，但其中的原则完全适用于其他类型的数据。本章末尾将提供一些有用的 R 包，以处理其他类型的数据。

### Prerequisites | 准备工作

In this chapter, you'll learn how to load flat files in R with the __readr__ package, which is part of the core tidyverse.

你将在本章中学习如何使用 readr 包将平面文件加载到 R 中，readr 也是 tidyverse 的核心 R
包之一。

```{r setup, message = FALSE}
library(tidyverse)
```

## Getting started | 入门

Most of readr's functions are concerned with turning flat files into data frames:

readr 的多数函数用于将平面文件转换为数据框。

* `read_csv()` reads comma delimited files, `read_csv2()` reads semicolon
  separated files (common in countries where `,` is used as the decimal place),
  `read_tsv()` reads tab delimited files, and `read_delim()` reads in files
  with any delimiter.
  
  read_csv() 读取逗号分隔文件、read_csv2() 读取分号分隔文件（这在用 , 表示小数位的国家非常普遍）、read_tsv() 读取制表符分隔文件、read_delim() 可以读取使用任意分隔符的文件。

* `read_fwf()` reads fixed width files. You can specify fields either by their
  widths with `fwf_widths()` or their position with `fwf_positions()`.
  `read_table()` reads a common variation of fixed width files where columns
  are separated by white space.
  
  read_fwf() 读取固定宽度的文件。既可以使用 fwf_widths() 函数按照宽度来设定域，也可以使用 fwf_positions() 函数按照位置来设定域。read_table() 读取固定宽度文件的一种常用变体，其中使用空白字符来分隔各列。

* `read_log()` reads Apache style log files. (But also check out
  [webreadr](https://github.com/Ironholds/webreadr) which is built on top
  of `read_log()` and provides many more helpful tools.)
  
read_log() 读取 Apache 风格的日志文件。（但需要检查是否安装了 webreadr 包，https:// github.com/Ironholds/webreadr，因为该包位于 read_log() 函数的开头，还可以提供很多有用的工具。）

These functions all have similar syntax: once you've mastered one, you can use the others with ease. For the rest of this chapter we'll focus on `read_csv()`. Not only are csv files one of the most common forms of data storage, but once you understand `read_csv()`, you can easily apply your knowledge to all the other functions in readr.

这些函数都具有同样的语法，你完全可以举一反三。在本章余下的内容中，我们将重点介绍 read_csv() 函数，不仅因为 CSV 文件是数据存储最常用的形式之一，还因为一旦掌握read_csv() 函数，你就可以将从中学到的知识非常轻松地应用于 readr 的其他函数。

The first argument to `read_csv()` is the most important: it's the path to the file to read.

read_csv() 函数的第一个参数是最重要的，该参数是要读取的文件的路径：

```{r, message = TRUE}
heights <- read_csv("data/heights.csv")
```

When you run `read_csv()` it prints out a column specification that gives the name and type of each column. That's an important part of readr, which we'll come back to in [parsing a file].

当运行 read_csv() 时，它会打印一份数据列说明，给出每个列的名称和类型。这是 readr
的一项重要功能，8.4 节将继续讨论这项功能。

You can also supply an inline csv file. This is useful for experimenting with readr and for creating reproducible examples to share with others:

你还可以提供一个行内 CSV 文件。这种文件非常适合使用 readr 进行实验，以及与他人分享可重现实例的情况。

```{r}
read_csv("a,b,c
1,2,3
4,5,6")
```

In both cases `read_csv()` uses the first line of the data for the column names, which is a very common convention. There are two cases where you might want to tweak this behaviour:

以上两种情况下，read_csv() 函数都使用数据的第一行作为列名称，这是一种常见做法。你或许想在以下两种情况下改变这种做法。

1.  Sometimes there are a few lines of metadata at the top of the file. You can
    use `skip = n` to skip the first `n` lines; or use `comment = "#"` to drop
    all lines that start with (e.g.) `#`.
    
    •	有时文件开头会有好几行元数据。你可以使用 skip = n 来跳过前 n 行；或者使用
comment = "#" 来丢弃所有以 # 开头的行：
    
    ```{r}
    read_csv("The first line of metadata
      The second line of metadata
      x,y,z
      1,2,3", skip = 2)
    
    read_csv("# A comment I want to skip
      x,y,z
      1,2,3", comment = "#")
    ```
    
1.  The data might not have column names. You can use `col_names = FALSE` to
    tell `read_csv()` not to treat the first row as headings, and instead
    label them sequentially from `X1` to `Xn`:
    
    •	数据没有列名称。可以使用 col_names = FALSE 来通知 read_csv() 不要将第一行作为列标题，而是将各列依次标注为 X1 至 Xn：
    
    ```{r}
    read_csv("1,2,3\n4,5,6", col_names = FALSE)
    ```
    
    (`"\n"` is a convenient shortcut for adding a new line. You'll learn more
    about it and other types of string escape in [string basics].)
    
    （"\n" 是非常便捷的快捷方式，用于添加新行。10.2 节介绍了更多关于 "\n" 和其他转义字符的知识。）
    
    Alternatively you can pass `col_names` a character vector which will be
    used as the column names:
    
    或者你也可以向 col_names 传递一个字符向量，以用作列名称：
    
    ```{r}
    read_csv("1,2,3\n4,5,6", col_names = c("x", "y", "z"))
    ```

Another option that commonly needs tweaking is `na`: this specifies the value (or values) that are used to represent missing values in your file:

另一个通常需要修改的选项是 na。它设定使用哪个值（或哪些值）来表示文件中的缺失值：

```{r}
read_csv("a,b,c\n1,2,.", na = ".")
```

This is all you need to know to read ~75% of CSV files that you'll encounter in practice. You can also easily adapt what you've learned to read tab separated files with `read_tsv()` and fixed width files with `read_fwf()`. To read in more challenging files, you'll need to learn more about how readr parses each column, turning them into R vectors.

如果掌握了以上知识，那么你就可以读取实际中遇到的约 75% 的文件了。你还可以轻松地扩展已经学到的知识，使用 read_tsv() 函数来读取制表符分隔文件，或使用 read_fwf() 函数来读取固定宽度的文件。如果想要读取难度更大的文件，则需要学习更多知识，了解readr 如何解析每一列，并将其转换为 R 中的向量。

### Compared to base R | 与R基础包进行比较

If you've used R before, you might wonder why we're not using `read.csv()`. There are a few good reasons to favour readr functions over the base equivalents:

如果以前使用过 R，那么你肯定很想知道我们为什么不使用 read.csv() 函数。相对于 R 基础包中具有同样功能的函数，我们更喜欢使用 readr 中的函数，理由如下。

* They are typically much faster (~10x) than their base equivalents.
  Long running jobs have a progress bar, so you can see what's happening. 
  If you're looking for raw speed, try `data.table::fread()`. It doesn't fit 
  quite so well into the tidyverse, but it can be quite a bit faster.
  
  一般来说，它们比基础模块中的函数速度更快（约快 10 倍）。因为运行时间很长的任务都会有一个进度条，所以你可以看到哪个函数更快。如果只考虑速度的话，还可以尝试使用 data.table::fread()。这个函数与 tidyverse 的兼容性不是很好，但确实更快一些。

* They produce tibbles, they don't convert character vectors to factors,
  use row names, or munge the column names. These are common sources of
  frustration with the base R functions.
  它们可以生成 tibble，并且不会将字符向量转换为因子，不使用行名称，也不会随意改动列名称。这些都是使用 R 基础包时常见的令人沮丧的事情。
  

* They are more reproducible. Base R functions inherit some behaviour from
  your operating system and environment variables, so import code that works 
  on your computer might not work on someone else's.
  
  它们更易于重复使用。R 基础包中的函数会继承操作系统的功能，并依赖环境变量，因此，可以在你的计算机上正常运行的代码在导入他人计算机时，不一定能正常运行。

### Exercises | 练习

1.  What function would you use to read a file where fields were separated with  
    "|"? 如果一个文件中的域是由“|”分隔的，那么应该使用哪个函数来读取这个文件？
    
1.  Apart from `file`, `skip`, and `comment`, what other arguments do
    `read_csv()` and `read_tsv()` have in common? 除了 file、skip 和 comment，还有哪些参数是 read_csv() 和 read_tsv() 这两个函数共有的？
    
1.  What are the most important arguments to `read_fwf()`? read_fwf() 函数中最重要的参数是什么？
   
1.  Sometimes strings in a CSV file contain commas. To prevent them from
    causing problems they need to be surrounded by a quoting character, like
    `"` or `'`. By default, `read_csv()` assumes that the quoting
    character will be `"`. What argument to `read_csv()` do you need to specify
    to read the following text into a data frame?
    
    有时 CSV 文件中的字符串会包含逗号。为了防止引发问题，需要用引号（如 " 或 '） 将逗号围起来。按照惯例，read_csv() 默认引号为 "，如果想要改变默认值，就要转而使用 read_delim() 函数。要想将以下文本读入一个数据框，需要设定哪些参数？
    
    ```{r, eval = FALSE}
    "x,y\n1,'a,b'"
    ```
    
1.  Identify what is wrong with each of the following inline CSV files. 
    What happens when you run the code?
    
    找出以下每个行内 CSV 文件中的错误。如果运行代码，会发生什么情况？
    
    ```{r, eval = FALSE}
    read_csv("a,b\n1,2,3\n4,5,6")
    read_csv("a,b,c\n1,2\n1,2,3,4")
    read_csv("a,b\n\"1")
    read_csv("a,b\n1,2\na,b")
    read_csv("a;b\n1;3")
    ```

## Parsing a vector | 解析向量

Before we get into the details of how readr reads files from disk, we need to take a little detour to talk about the `parse_*()` functions. These functions take a character vector and return a more specialised vector like a logical, integer, or date:

在详细介绍 readr 如何从磁盘读取文件前，我们需要先讨论一下 parse_*() 函数族。这些函数接受一个字符向量，并返回一个特定向量，如逻辑、整数或日期向量：

```{r}
str(parse_logical(c("TRUE", "FALSE", "NA")))
str(parse_integer(c("1", "2", "3")))
str(parse_date(c("2010-01-01", "1979-10-14")))
```

These functions are useful in their own right, but are also an important building block for readr. Once you've learned how the individual parsers work in this section, we'll circle back and see how they fit together to parse a complete file in the next section.

这些函数各司其职，且都是 readr 的重要组成部分。一旦掌握了本节中这些单个解析函数的用法，我们就可以继续讨论如何综合使用它们来解析整个文件了。

Like all functions in the tidyverse, the `parse_*()` functions are uniform: the first argument is a character vector to parse, and the `na` argument specifies which strings should be treated as missing:

和 tidyverse 中的所有函数一样，parse_*() 函数族的用法是一致的。第一个参数是需要解析的字符向量，na 参数设定了哪些字符串应该当作缺失值来处理：

```{r}
parse_integer(c("1", "231", ".", "456"), na = ".")
```

If parsing fails, you'll get a warning:
如果解析失败，你会收到一条警告：

```{r}
x <- parse_integer(c("123", "345", "abc", "123.45"))
```

And the failures will be missing in the output:
解析失败的值在输出中是以缺失值的形式存在的：

```{r}
x
```

If there are many parsing failures, you'll need to use `problems()` to get the complete set. This returns a tibble, which you can then manipulate with dplyr.

如果解析失败的值很多，那么就应该使用 problems() 函数来获取完整的失败信息集合。这个函数会返回一个 tibble，你可以使用 dplyr 包来进行处理：

```{r}
problems(x)
```

Using parsers is mostly a matter of understanding what's available and how they deal with different types of input. There are eight particularly important parsers:

在解析函数的使用方面，最重要的是要知道有哪些解析函数，以及每种解析函数用来处理哪种类型的输入。具体来说，重要的解析函数有 8 种。

1.  `parse_logical()` and `parse_integer()` parse logicals and integers
    respectively. There's basically nothing that can go wrong with these
    parsers so I won't describe them here further.
    
    •	parse_logical() 和 parse_integer() 函数分别解析逻辑值和整数。因为这两个解析函数基本不会出现问题，所以我们不再进行更多介绍。
    
1.  `parse_double()` is a strict numeric parser, and `parse_number()` 
    is a flexible numeric parser. These are more complicated than you might
    expect because different parts of the world write numbers in different
    ways.
    
    •	parse_double() 是严格的数值型解析函数，parse_number() 则是灵活的数值型解析函数。这两个函数要比你预想的更复杂，因为世界各地书写数值的方式不尽相同。
    
1.  `parse_character()` seems so simple that it shouldn't be necessary. But
    one complication makes it quite important: character encodings.
    
    •	parse_character() 函数似乎太过简单，甚至没必要存在。但一个棘手的问题使得这个函数变得非常重要：字符编码。

1.  `parse_factor()` create factors, the data structure that R uses to represent
    categorical variables with fixed and known values.
    
    •	parse_factor() 函数可以创建因子，R 使用这种数据结构来表示分类变量，该变量具有固定数目的已知值。

1.  `parse_datetime()`, `parse_date()`, and `parse_time()` allow you to
    parse various date & time specifications. These are the most complicated
    because there are so many different ways of writing dates.
    
    •	parse_datetime()、parse_date() 和 parse_time() 函数可以解析不同类型的日期和时间。它们是最复杂的，因为有太多不同的日期书写形式。

The following sections describe these parsers in more detail. 我们将在以下各节中更加详细地介绍这些解析函数。

### Numbers | 数值

It seems like it should be straightforward to parse a number, but three problems make it tricky:

解析数值似乎是非常直截了当的，但以下 3 个问题增加了数值解析的复杂性。

1. People write numbers differently in different parts of the world.
   For example, some countries use `.` in between the integer and fractional 
   parts of a real number, while others use `,`.
   
   •	世界各地的人们书写数值的方式不尽相同。例如，有些国家使用 . 来分隔实数中的整数和小数部分，而有些国家则使用 ,。
   
1. Numbers are often surrounded by other characters that provide some
   context, like "$1000" or "10%".
   
   •	数值周围经常有表示某种意义的其他字符，如 $1000 或 10%。

1. Numbers often contain "grouping" characters to make them easier to read, 
   like "1,000,000", and these grouping characters vary around the world.
   
   •	数值经常包含“分组”，以便更易读，如 1 000 000，而且世界各地用来分组的字符也不尽相同。

To address the first problem, readr has the notion of a "locale", an object that specifies parsing options that differ from place to place. When parsing numbers, the most important option is the character you use for the decimal mark. You can override the default value of `.` by creating a new locale and setting the `decimal_mark` argument:

为了解决第一个问题，readr 使用了“地区”这一概念，这是可以按照不同地区设置解析选项的一个对象。在解析数值时，最重要的选项就是用来表示小数点的字符。通过创建一个新的地区对象并设定 decimal_mark 参数，可以覆盖 . 的默认值：

```{r}
parse_double("1.23")
parse_double("1,23", locale = locale(decimal_mark = ","))
```

readr's default locale is US-centric, because generally R is US-centric (i.e. the documentation of base R is written in American English). An alternative approach would be to try and guess the defaults from your operating system. This is hard to do well, and, more importantly, makes your code fragile: even if it works on your computer, it might fail when you email it to a colleague in another country.

readr 的默认地区是 US-centric，因为 R 是以美国为中心的（也就是说，R 基础包的文档是用美式英语写成的）。获取默认地区设置的另一种方法是利用操作系统，但这种方法很难奏效，更重要的是，这会让你的代码很脆弱：即使可以在你的计算机上良好运行，但通过电子邮件分享给另一个国家的同事时，就可能失效。

`parse_number()` addresses the second problem: it ignores non-numeric characters before and after the number. This is particularly useful for currencies and percentages, but also works to extract numbers embedded in text.

parse_number() 解决了第二个问题：它可以忽略数值前后的非数值型字符。这个函数特别适合处理货币和百分比，也可以提取嵌在文本中的数值：

```{r}
parse_number("$100")
parse_number("20%")
parse_number("It cost $123.45")
```

The final problem is addressed by the combination of `parse_number()` and the locale as `parse_number()` will ignore the "grouping mark":

组合使用 parse_number() 和地区设置可以解决最后一个问题，因为 parse_number() 可以忽略“分组符号”：

```{r}
# Used in America
# 适用于美国
parse_number("$123,456,789")

# Used in many parts of Europe
# 适用于多数欧洲国家
parse_number("123.456.789", locale = locale(grouping_mark = "."))

# Used in Switzerland
# 适用于瑞士
parse_number("123'456'789", locale = locale(grouping_mark = "'"))
```

### Strings | 字符串 {#readr-strings}

It seems like `parse_character()` should be really simple --- it could just return its input. Unfortunately life isn't so simple, as there are multiple ways to represent the same string. To understand what's going on, we need to dive into the details of how computers represent strings. In R, we can get at the underlying representation of a string using `charToRaw()`:

parse_character() 函数似乎真的很简单，只要返回输入值就可以了。问题是生活没这么简单，因为同一个字符串有多种表示方式。为了理解个中缘由，我们需要深入介绍一下计算机是如何表示字符串的。在 R 中，我们可以使用 charToRaw() 函数获得一个字符串的底层表示：

```{r}
charToRaw("Hadley")
```

Each hexadecimal number represents a byte of information: `48` is H, `61` is a, and so on. The mapping from hexadecimal number to character is called the encoding, and in this case the encoding is called ASCII. ASCII does a great job of representing English characters, because it's the __American__ Standard Code for Information Interchange.

每个十六进制数表示信息的一个字节：48 是 H、61 是 a 等。从十六进制数到字符的这种映射称为编码，这个示例中的编码方式称为 ASCII。ASCII 可以非常好地表示英文字符，因为它就是美国信息交换标准代码（American Standard Code for Information Interchange）的缩写。

Things get more complicated for languages other than English. In the early days of computing there were many competing standards for encoding non-English characters, and to correctly interpret a string you needed to know both the values and the encoding. For example, two common encodings are Latin1 (aka ISO-8859-1, used for Western European languages) and Latin2 (aka ISO-8859-2, used for Eastern European languages). In Latin1, the byte `b1` is "±", but in Latin2, it's "ą"! Fortunately, today there is one standard that is supported almost everywhere: UTF-8. UTF-8 can encode just about every character used by humans today, as well as many extra symbols (like emoji!).

对于英语之外的其他语言，事情就变得更加复杂了。计算机发展的早期阶段有很多为非英语字符进行编码的标准，它们之间甚至是相互矛盾的。要想正确表示一个字符串，不仅需要知道它的值，还要知道其编码方式。例如，Latin1（即 ISO-8859-1，用于西欧语言） 和 Latin2（即 ISO-8859-2，用于东欧语言）是两种常用的编码方式。字节 b1 在 Latin1 中表示“±”，但在 Latin2 中则表示“ą”！好在现在有一种几乎所有语言都支持的标准： UTF-8。UTF-8 可以为现在人类使用的所有字符进行编码，同时还支持很多特殊字符（如表情符号！）。

readr uses UTF-8 everywhere: it assumes your data is UTF-8 encoded when you read it, and always uses it when writing. This is a good default, but will fail for data produced by older systems that don't understand UTF-8. If this happens to you, your strings will look weird when you print them. Sometimes just one or two characters might be messed up; other times you'll get complete gibberish. For example:

readr 全面支持 UTF-8：当读取数据时，它假设数据是 UTF-8 编码的，并总是使用 UTF-8 编码写入数据。这是非常好的默认方式，但对于从不支持 UTF-8 的那些旧系统中产生的数据则无能为力。遇到这种情况时，你的字符串打印出来就是一堆乱码。有时只有一两个字符是乱码；有时则完全不知所云。例如：

```{r}
x1 <- "El Ni\xf1o was particularly bad this year"
x2 <- "\x82\xb1\x82\xf1\x82\xc9\x82\xbf\x82\xcd"

x1
x2
```

To fix the problem you need to specify the encoding in `parse_character()`:

要想解决这个问题，需要在 parse_character() 函数中设定编码方式：

```{r}
parse_character(x1, locale = locale(encoding = "Latin1"))
parse_character(x2, locale = locale(encoding = "Shift-JIS"))
```

How do you find the correct encoding? If you're lucky, it'll be included somewhere in the data documentation. Unfortunately, that's rarely the case, so readr provides  `guess_encoding()` to help you figure it out. It's not foolproof, and it works better when you have lots of text (unlike here), but it's a reasonable place to start. Expect to try a few different encodings before you find the right one.

如何才能找到正确的编码方式呢？如果足够幸运，那么编码方式可能就写在数据文档中。遗憾的是这种情况非常罕见，因此 readr 提供了 guess_encoding() 函数来帮助你找出编码方式。但这个函数并非万无一失，如果有大量文本（不像本例），效果就会更好，它确实是一个良好的起点。希望试验几次后，你就能够找到正确的编码方式：

```{r}
guess_encoding(charToRaw(x1))
guess_encoding(charToRaw(x2))
```

The first argument to `guess_encoding()` can either be a path to a file, or, as in this case, a raw vector (useful if the strings are already in R).

guess_encoding() 的第一个参数可以是一个文件路径，也可以是一个原始向量（适用于字符串已经在 R 中的情况），就像本示例一样。

Encodings are a rich and complex topic, and I've only scratched the surface here. If you'd like to learn more I'd recommend reading the detailed explanation at <http://kunststube.net/encoding/>.

编码问题博大精深，这里我们只是蜻蜓点水式地介绍一下。如果想要学习更多相关知识， 我们推荐你阅读 http://kunststube.net/encoding/ 中的详细说明。

### Factors | 因子 {#readr-factors}

R uses factors to represent categorical variables that have a known set of possible values. Give `parse_factor()` a vector of known `levels` to generate a warning whenever an unexpected value is present:

R 使用因子表示取值范围是已知集合的分类变量。如果 parse_factor() 函数的 levels 参数被赋予一个已知向量，那么只要存在向量中没有的值，就会生成一条警告：

```{r}
fruit <- c("apple", "banana")
parse_factor(c("apple", "banana", "bananana"), levels = fruit)
```

But if you have many problematic entries, it's often easier to leave as character vectors and then use the tools you'll learn about in [strings] and [factors] to clean them up.

如果有很多问题条目的话，通常更简单的做法是将它们作为字符向量，然后使用将在字符串和因子中介绍的工具来进行数据清理。


### Dates, date-times, and times | 日期、日期时间与时间 {#readr-datetimes}

You pick between three parsers depending on whether you want a date (the number of days since 1970-01-01), a date-time (the number of seconds since midnight 1970-01-01), or a time (the number of seconds since midnight). When called without any additional arguments:

根据需要的是日期型数据（从 1970-01-01 开始的天数）、日期时间型数据（从 1970-01-01
午夜开始的秒数），或者是时间型数据（从午夜开始的秒数），我们可以在 3 种解析函数之间进行选择。在没有使用任何附加参数时调用，具体情况如下。

*   `parse_datetime()` expects an ISO8601 date-time. ISO8601 is an
    international standard in which the components of a date are
    organised from biggest to smallest: year, month, day, hour, minute, 
    second.
    
    •	parse_datetime() 期待的是符合 ISO 8601 标准的日期时间。ISO 8601 是一种国际标准， 其中日期的各个部分按从大到小的顺序排列，即年、月、日、小时、分钟、秒：
    
    ```{r}
    parse_datetime("2010-10-01T2010")
    # If time is omitted, it will be set to midnight
    # 如果时间被省略了，那么它就会被设置为午夜
    parse_datetime("20101010")
    ```
    
    This is the most important date/time standard, and if you work with
    dates and times frequently, I recommend reading
    <https://en.wikipedia.org/wiki/ISO_8601>
    
    这是最重要的日期 / 时间标准，如果经常使用日期和时间，我们建议你阅读一下维基百科上的 ISO 8601 标准。
    
*   `parse_date()` expects a four digit year, a `-` or `/`, the month, a `-` 
    or `/`, then the day:
    
    •	parse_date() 期待的是四位数的年份、一个 - 或 /、月、一个 - 或 /，然后是日：
    
    ```{r}
    parse_date("2010-10-01")
    ```

*   `parse_time()` expects the hour, `:`, minutes, optionally `:` and seconds, 
    and an optional am/pm specifier:
    
    •	parse_time() 期待的是小时、:、分钟、可选的 : 和秒，以及一个可选的 a.m./p.m. 标识符：
  
    ```{r}
    library(hms)
    parse_time("01:10 am")
    parse_time("20:10:01")
    ```
    
    Base R doesn't have a great built in class for time data, so we use 
    the one provided in the hms package.
    
    因为 R 基础包中没有能够很好表示时间数据的内置类，所以我们使用 hms 包提供的时间类。

If these defaults don't work for your data you can supply your own date-time `format`, built up of the following pieces:

如果这些默认设置不适合你的数据，那么你可以提供自己的日期时间格式，格式由以下各部分组成。

Year 年
: `%Y` (4 digits 4 位数). 
: `%y` (2 digits 2 位数); 00-69 -> 2000-2069, 70-99 -> 1970-1999.

Month 月
: `%m` (2 digits 2 位数).
: `%b` (abbreviated name, like "Jan" 简写名称，如 Jan).
: `%B` (full name, "January" 完整名称，如 January).

Day 日
: `%d` (2 digits 1 位或 2 位数).
: `%e` (optional leading space 2 位数).

Time 时间
: `%H` 0-23 hour 小时.
: `%I` 0-12, must be used with `%p` 小时，必须和 %p 一起使用.
: `%p` AM/PM indicator 表示 a.m./p.m.
: `%M` minutes 分钟.
: `%S` integer seconds 整数秒.
: `%OS` real seconds 实数秒. 
: `%Z` Time zone (as name, e.g. `America/Chicago`). Beware of abbreviations:
  if you're American, note that "EST" is a Canadian time zone that does not
  have daylight savings time. It is _not_ Eastern Standard Time! We'll
  come back to this [time zones].
  
  （时区，America/Chicage 这样的名称）。注意，要当心缩写。如果你是美国人，注意EST 是加拿大没有夏时制的一个时区。它表示东部标准时间！我们还会在 12.5 节中继续讨论这个话题。
  
: `%z` (as offset from UTC 与国际标准时间的时差, e.g. 如 `+0800`). 

Non-digits 非数值字符
: `%.` skips one non-digit character 跳过一个非数值字符.
: `%*` skips any number of non-digits 跳过所有非数值字符.

The best way to figure out the correct format is to create a few examples in a character vector, and test with one of the parsing functions. For example:

找出正确格式的最好方法是创建几个解析字符向量的示例，并使用某种解析函数进行测试。例如：

```{r}
parse_date("01/02/15", "%m/%d/%y")
parse_date("01/02/15", "%d/%m/%y")
parse_date("01/02/15", "%y/%m/%d")
```

If you're using `%b` or `%B` with non-English month names, you'll need to set the  `lang` argument to `locale()`. See the list of built-in languages in `date_names_langs()`, or if your language is not already included, create your own with `date_names()`.

如果对非英语月份名称使用 %b 或 %B，那么你就需要在 locale() 函数中设置 lang 参数。查看 date_names_langs() 函数中的内置语言列表，如果你的语言没有包括在内，那么可以使用 date_names() 函数创建自己的月份和日期名称：

```{r}
parse_date("1 janvier 2015", "%d %B %Y", locale = locale("fr"))
```

### Exercises | 8.3.1	练习

1.  What are the most important arguments to `locale()`? locale() 函数中最重要的参数是什么？

1.  What happens if you try and set `decimal_mark` and `grouping_mark` 
    to the same character? What happens to the default value of 
    `grouping_mark` when you set `decimal_mark` to ","? What happens
    to the default value of `decimal_mark` when you set the `grouping_mark`
    to "."?
    
    如果将 decimal_mark 和 grouping_mark 设为同一个字符，会发生什么情况？如果将 decimal_ mark 设为 ,，grouping_mark 的默认值会发生什么变化？如果将 grouping_mark 设为 .， decimal_mark 的默认值会发生什么变化？

1.  I didn't discuss the `date_format` and `time_format` options to
    `locale()`. What do they do? Construct an example that shows when 
    they might be useful.
    
    我们没有讨论过 locale() 函数的 date_format 和 time_format 选项，它们的作用是什么？构建一个示例，说明它们在何种情况下是有用的？

1.  If you live outside the US, create a new locale object that encapsulates 
    the settings for the types of file you read most commonly.
    
    如果你不是居住在美国，创建一个新的地区对象，并封装你最常读取的文件类型的相关设置。
    
1.  What's the difference between `read_csv()` and `read_csv2()`?
read_csv() 和 read_csv2() 之间的区别是什么？

    
1.  What are the most common encodings used in Europe? What are the
    most common encodings used in Asia? Do some googling to find out.
    
    欧洲最常用的编码方式是什么？亚洲最常用的编码方式是什么？可以使用 google 找出答案。

1.  Generate the correct format string to parse each of the following 
    dates and times:
    
    生成正确形式的字符串来解析以下日期和时间。
    
    ```{r}
    d1 <- "January 1, 2010"
    d2 <- "2015-Mar-07"
    d3 <- "06-Jun-2017"
    d4 <- c("August 19 (2015)", "July 1 (2015)")
    d5 <- "12/30/14" # Dec 30, 2014
    t1 <- "1705"
    t2 <- "11:15:10.12 PM"
    ```

## Parsing a file | 解析文件

Now that you've learned how to parse an individual vector, it's time to return to the beginning and explore how readr parses a file. There are two new things that you'll learn about in this section:

现在你已经学会了如何解析单个向量，接下来我们就回到本章的最初目标，研究 readr 是如何解析文件的。你将在本节中学到以下两种新技能。

1. How readr automatically guesses the type of each column.
•	readr 如何自动猜出文件每列的数据类型。

1. How to override the default specification.
•	如何修改默认设置。


### Strategy | 策略

readr uses a heuristic to figure out the type of each column: it reads the first 1000 rows and uses some (moderately conservative) heuristics to figure out the type of each column. You can emulate this process with a character vector using `guess_parser()`, which returns readr's best guess, and `parse_guess()` which uses that guess to parse the column:

readr 使用一种启发式过程来确定每列的类型：先读取文件的前 1000 行，然后使用（相对保守的）某种启发式算法确定每列的类型。可以使用字符向量模拟这个过程，先使用 guess_ parser() 函数返回 readr 最可信的猜测，接着 parse_guess() 函数使用这个猜测来解析列：

```{r}
guess_parser("2010-10-01")
guess_parser("15:01")
guess_parser(c("TRUE", "FALSE"))
guess_parser(c("1", "5", "9"))
guess_parser(c("12,352,561"))

str(parse_guess("2010-10-10"))
```

The heuristic tries each of the following types, stopping when it finds a match:

这个启发式过程会尝试以下每种数据类型，直至找到匹配的类型。

* logical 逻辑值: contains only "F", "T", "FALSE", or "TRUE". 只包括 F、T、FALSE 和 TRUE。
* integer 整数: contains only numeric characters (and `-`). 只包括数值型字符（以及 -）。
* double 双精度浮点数: contains only valid doubles (including numbers like `4.5e-5`). 只包括有效的双精度浮点数（也包括 4.5e-5 这样的数值）。
* number 数值: contains valid doubles with the grouping mark inside. 只包括带有分组符号的有效双精度浮点数。
* time 时间: matches the default `time_format`. 与默认的 time_format 匹配的值。
* date 日期: matches the default `date_format`. 与默认的 date_format 匹配的值。
* date-time 日期时间: any ISO8601 date. 符合 ISO 8601 标准的任何日期。

If none of these rules apply, then the column will stay as a vector of strings.

如果以上类型均不匹配，那么这一列就还是一个字符串向量。

### Problems | 问题

These defaults don't always work for larger files. There are two basic problems:

这些默认设置对更大的文件并不是一直有效的。以下是两个主要问题。

1.  The first thousand rows might be a special case, and readr guesses
    a type that is not sufficiently general. For example, you might have 
    a column of doubles that only contains integers in the first 1000 rows. 
    
    •	前 1000 行可能是一种特殊情况，readr 猜测出的类型不足以代表整个文件。例如，一列双精度数值的前 1000 行可能都是整数。

1.  The column might contain a lot of missing values. If the first 1000
    rows contain only `NA`s, readr will guess that it's a logical 
    vector, whereas you probably want to parse it as something more
    specific.
    
    •	列中可能含有大量缺失值。如果前 1000 行中都是 NA，那么 readr 会猜测这是一个字符向量，但你其实想将这一列解析为更具体的值。

readr contains a challenging CSV that illustrates both of these problems:

readr 中包含了一份非常有挑战性的 CSV 文件，该文件可以说明以上两个问题。

```{r}
challenge <- read_csv(readr_example("challenge.csv"))
```

(Note the use of `readr_example()` which finds the path to one of the files included with the package)

（注意 readr_example() 函数的用法，它可以找到包含在 R 包中的文件的路径。）

There are two printed outputs: the column specification generated by looking at the first 1000 rows, and the first five parsing failures. It's always a good idea to explicitly pull out the `problems()`, so you can explore them in more depth:

以上的输出可以分为两部分：从前 1000 行中猜测出的列类型与前 5 条解析失败记录。我们总是应该使用 problems() 函数明确地列出这些失败记录，以便更加深入地探究其中的问题：

```{r}
problems(challenge)
```

A good strategy is to work column by column until there are no problems remaining. Here we can see that there are a lot of parsing problems with the `y` column. If we look at the last few rows, you'll see that they're dates stored in a character vector:  

一列列地处理，直至解决所有问题，是一种良好策略。这里我们可以看到 y 列中存在大量解析问题。

```{r}
tail(challenge)
```

That suggests we need to use a date parser instead. To fix the call, start by copying and pasting the column specification into your original call:

这说明我们应该使用双精度解析函数。为了解决这个问题，首先，复制列类型并将其粘贴到初始调用中：

```{r, eval = FALSE}
challenge <- read_csv(
  readr_example("challenge.csv"), 
  col_types = cols(
    x = col_double(),
    y = col_logical()
  )
)
```

Then you can fix the type of the `y` column by specifying that `y` is a date column:
设定 y 为日期列可以解决这个问题：

```{r}
challenge <- read_csv(
  readr_example("challenge.csv"), 
  col_types = cols(
    x = col_double(),
    y = col_date()
  )
)
tail(challenge)
```

Every `parse_xyz()` function has a corresponding `col_xyz()` function. You use `parse_xyz()` when the data is in a character vector in R already; you use `col_xyz()` when you want to tell readr how to load the data.

每个 parse_xyz() 函数都有一个对应的 col_xyz() 函数。如果数据已经保存在 R 的字符向量中， 那么你可以使用 parse_xyz()；如果想要告诉 readr 如何加载数据，则应该使用 col_xyz()。

I highly recommend always supplying `col_types`, building up from the print-out provided by readr. This ensures that you have a consistent and reproducible data import script. If you rely on the default guesses and your data changes, readr will continue to read it in. If you want to be really strict, use `stop_for_problems()`: that will throw an error and stop your script if there are any parsing problems.

我们强烈建议你总是提供 col_types 参数，从 readr 打印出的输出中可以知道它的值。这可以确保数据导入脚本的一致性，并可以重复使用。如果不提供这个参数，而是依赖猜测的类型，那么当数据发生变化时，readr 会继续读入数据。如果想要严格解析，可以使用stop_for_problems() 函数：当出现任何解析问题时，它会抛出一个错误，并终止脚本。

### Other strategies | 其他策略

There are a few other general strategies to help you parse files:

我们再介绍其他几种有助于解析文件的通用策略。

*   In the previous example, we just got unlucky: if we look at just
    one more row than the default, we can correctly parse in one shot:
    
    •	在前面的示例中，我们的运气太差了：如果比默认方式再多检查 1 行，我们就能一蹴而就，解析成功。
   
    ```{r}
    challenge2 <- read_csv(readr_example("challenge.csv"), guess_max = 1001)
    challenge2
    ```

*   Sometimes it's easier to diagnose problems if you just read in all
    the columns as character vectors:
    
    •	有时如果将所有列都作为字符向量读入的话，会更容易诊断出问题：
   
    ```{r}
    challenge2 <- read_csv(readr_example("challenge.csv"), 
      col_types = cols(.default = col_character())
    )
    ```
    
    This is particularly useful in conjunction with `type_convert()`,
    which applies the parsing heuristics to the character columns in a data
    frame.
    
    这种方式结合 type_convert() 函数使用时特别有效，后者可以在数据框的字符列上应用启发式解析过程：

    ```{r}
    df <- tribble(
      ~x,  ~y,
      "1", "1.21",
      "2", "2.32",
      "3", "4.56"
    )
    df
    
    # Note the column types
    # 注意列类型
    type_convert(df)
    ```
    
*   If you're reading a very large file, you might want to set `n_max` to
    a smallish number like 10,000 or 100,000. That will accelerate your 
    iterations while you eliminate common problems.
    
    •	如果正在读取一个非常大的文件，那么你应该将 n_max 设置为一个较小的数，比如 10 000 或者 100 000。这可以让你在解决常见问题时加快重复试验的过程。

*   If you're having major parsing problems, sometimes it's easier
    to just read into a character vector of lines with `read_lines()`,
    or even a character vector of length 1 with `read_file()`. Then you
    can use the string parsing skills you'll learn later to parse
    more exotic formats.
    
    •	如果遇到严重的解析问题，有时使用 read_lines() 函数按行读入字符向量会更容易， 甚至可以使用 read_file() 函数读入一个长度为 1 的字符向量。接着你可以使用后面将学到的字符串解析技能来解析各种各样的数据形式。

## Writing to a file | 写入文件

readr also comes with two useful functions for writing data back to disk: `write_csv()` and `write_tsv()`. Both functions increase the chances of the output file being read back in correctly by:

readr 还提供了两个非常有用的函数，用于将数据写回到磁盘：write_csv() 和 write_ tsv()。这两个函数输出的文件能够顺利读取的概率更高，因为：

* Always encoding strings in UTF-8. 
它们总是使用 UTF-8 对字符串进行编码；
  
* Saving dates and date-times in ISO8601 format so they are easily
  parsed elsewhere. 
  它们使用 ISO 8601 格式来保存日期和日期时间数据，以便这些数据不论在何种环境下都更容易解析。

If you want to export a csv file to Excel, use `write_excel_csv()` --- this writes a special character (a "byte order mark") at the start of the file which tells Excel that you're using the UTF-8 encoding.

如果想要将 CSV 文件导为 Excel 文件，可以使用 write_excel_csv() 函数，该函数会在文件开头写入一个特殊字符（字节顺序标记），告诉 Excel 这个文件使用的是 UTF-8 编码。

The most important arguments are `x` (the data frame to save), and `path` (the location to save it). You can also specify how missing values are written with `na`, and if you want to `append` to an existing file.

这几个函数中最重要的参数是 x（要保存的数据框）和 path（保存文件的位置）。还可以使用 na 参数设定如何写入缺失值，如果想要追加到现有的文件，需要设置 append 参数：

```{r, eval = FALSE}
write_csv(challenge, "challenge.csv")
```

Note that the type information is lost when you save to csv:

注意，当保存为 CSV 文件时，类型信息就丢失了：

```{r, warning = FALSE}
challenge
write_csv(challenge, "challenge-2.csv")
read_csv("challenge-2.csv")
```

This makes CSVs a little unreliable for caching interim results---you need to recreate the column specification every time you load in. There are two alternatives:

这使得 CSV 文件在暂存临时结果时有些不可靠——每次加载时都要重建列类型。以下是两种替代方式。

1.  `write_rds()` and `read_rds()` are uniform wrappers around the base 
    functions `readRDS()` and `saveRDS()`. These store data in R's custom 
    binary format called RDS:
    
    •	write_rds() 和 read_rds() 函数是对基础函数 readRDS() 和 saveRDS() 的统一包装。前者可以将数据保存为 R 自定义的二进制格式，称为 RDS 格式：
    
    ```{r}
    write_rds(challenge, "challenge.rds")
    read_rds("challenge.rds")
    ```
  
1.  The feather package implements a fast binary file format that can
    be shared across programming languages:
    
    •	feather 包实现了一种快速二进制格式，可以在多个编程语言间共享：
    
    ```{r, eval = FALSE}
    library(feather)
    write_feather(challenge, "challenge.feather")
    read_feather("challenge.feather")
    #> # A tibble: 2,000 x 2
    #>       x      y
    #>   <dbl> <date>
    #> 1   404   <NA>
    #> 2  4172   <NA>
    #> 3  3004   <NA>
    #> 4   787   <NA>
    #> 5    37   <NA>
    #> 6  2332   <NA>
    #> # ... with 1,994 more rows
    ```

Feather tends to be faster than RDS and is usable outside of R. RDS supports list-columns (which you'll learn about in [many models]); feather currently does not.

feather 要比 RDS 速度更快，而且可以在 R 之外使用。RDS 支持列表列（我们将在更多模型中介绍），feather 目前还不行。

```{r, include = FALSE}
file.remove("challenge-2.csv")
file.remove("challenge.rds")
```

## Other types of data | 其他类型的数据

To get other types of data into R, we recommend starting with the tidyverse packages listed below. They're certainly not perfect, but they are a good place to start. For rectangular data:

要想将其他类型的数据导入R 中，我们建议首先从下列的tidyverse 包开始。它们当然远非完美，但确实是一个很好的起点。对矩形数据来说：

* __haven__ reads SPSS, Stata, and SAS files. haven 可以读取 SPSS、Stata 和 SAS 文件；

* __readxl__ reads excel files (both `.xls` and `.xlsx`). readxl 可以读取 Excel 文件（.xls 和 .xlsx 均可）；

* __DBI__, along with a database specific backend (e.g. __RMySQL__, 
  __RSQLite__, __RPostgreSQL__ etc) allows you to run SQL queries against a 
  database and return a data frame.
  
  •	配合专用的数据库后端程序（如RMySQL、RSQLite、RPostgreSQL 等），DBI 可以对相应数据库进行 SQL 查询，并返回一个数据框。

For hierarchical data: use __jsonlite__ (by Jeroen Ooms) for json, and __xml2__ for XML. Jenny Bryan has some excellent worked examples at <https://jennybc.github.io/purrr-tutorial/>.

对于层次数据，可以使用 jsonlite（由 JeroenOoms 开发）读取 JSON 串，使用 xml2 读取 XML 文件。Jenny Bryan 在 https://jennybc.github.io/purrr-tutorial/ 中提供了一些非常好的示例。

For other file types, try the [R data import/export manual](https://cran.r-project.org/doc/manuals/r-release/R-data.html) and the [__rio__](https://github.com/leeper/rio) package.

对于其他的文件类型，可以学习一下 R 数据导入 / 导出手册（https://cran.r-project.org/doc/ manuals/r-release/R-data.html），以及 rio 包（https://github.com/leeper/rio）。
